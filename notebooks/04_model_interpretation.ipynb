{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiomeML - GNN Model Interpretation\n",
    "\n",
    "## Summary\n",
    "- Load a trained model and test dataset for interpretation.\n",
    "- Compute node importance, embeddings, and error analysis.\n",
    "- Save interpretation artifacts under `{DISEASE}_analysis_output/`.\n",
    "\n",
    "\n",
    "This notebook provides tools for interpreting trained GNN models:\n",
    "\n",
    "1. Node importance analysis (which microbes drive predictions)\n",
    "2. Prediction explanation for individual samples\n",
    "3. Embedding visualization to inspect sample separation\n",
    "4. Error analysis for misclassifications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Trained model from `03_model_training.ipynb`\n",
    "- Processed graphs and labels in `{DISEASE}_analysis_output/`\n",
    "- Set `EXPERIMENT_CONFIG_PATH` or `DISEASE` to select the target disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "                                                                                    \n",
    "import yaml\n",
    "\n",
    "EXPERIMENT_CONFIG = None\n",
    "exp_config_path = os.environ.get('EXPERIMENT_CONFIG_PATH')\n",
    "\n",
    "if exp_config_path and Path(exp_config_path).exists():\n",
    "    print(f\"Loading experiment config from: {exp_config_path}\")\n",
    "    with open(exp_config_path, 'r') as f:\n",
    "        EXPERIMENT_CONFIG = yaml.safe_load(f)\n",
    "    print(f\"  Loaded experiment: {EXPERIMENT_CONFIG.get('name', 'unknown')}\")\n",
    "else:\n",
    "    print(\"No EXPERIMENT_CONFIG_PATH set - using default settings\")\n",
    "from src.model_interpretation import (\n",
    "    compute_node_gradients,\n",
    "    compute_integrated_gradients,\n",
    "    get_top_important_nodes,\n",
    "    aggregate_importance_across_samples,\n",
    "    analyze_prediction,\n",
    "    batch_analyze_predictions,\n",
    "    visualize_node_importance,\n",
    "    visualize_embedding_space,\n",
    "    save_interpretation_results\n",
    ")\n",
    "\n",
    "print(\"Imports loaded successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data\n",
    "### Load model artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"baseline\"\n",
    "\n",
    "                                                                     \n",
    "if EXPERIMENT_CONFIG is not None:\n",
    "    DISEASE = EXPERIMENT_CONFIG.get('disease') or EXPERIMENT_CONFIG.get('data_extraction', {}).get('disease', 'IBD')\n",
    "else:\n",
    "    import os\n",
    "    DISEASE = os.environ.get('DISEASE', 'IBD')\n",
    "\n",
    "print(f\"Disease: {DISEASE}\")\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "experiment_dir = project_root / \"experiments\" / EXPERIMENT_NAME\n",
    "output_dir = Path(f\"{DISEASE}_analysis_output\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_path = output_dir / \"models\" / \"best_model.pt\"\n",
    "dataset_path = output_dir / \"pytorch_geometric\" / f\"{DISEASE.lower()}_dataset.pt\"\n",
    "graphs_path = output_dir / \"graphs\" / f\"nx_graphs_{DISEASE}.pkl\"\n",
    "metadata_path = output_dir / \"graphs\" / f\"graph_metadata_{DISEASE}.csv\"\n",
    "\n",
    "print(f\"\\nChecking files:\")\n",
    "print(f\"  Model: {model_path.exists()}\")\n",
    "print(f\"  Dataset: {dataset_path.exists()}\")\n",
    "print(f\"  Graphs: {graphs_path.exists()}\")\n",
    "print(f\"  Metadata: {metadata_path.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                          \n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from src.models import (\n",
    "    GNN_GCN, GNN_GINEConv, GNN_GAT, GNN_GraphSAGE, \n",
    "    EdgeCentricRGCN, MLP_Baseline, CNN_Baseline, get_model\n",
    ")\n",
    "\n",
    "                                           \n",
    "MODEL_CLASSES = {\n",
    "    'GCN': GNN_GCN,\n",
    "    'GINEConv': GNN_GINEConv,\n",
    "    'GAT': GNN_GAT,\n",
    "    'GraphSAGE': GNN_GraphSAGE,\n",
    "    'EdgeCentricRGCN': EdgeCentricRGCN,\n",
    "    'MLP': MLP_Baseline,\n",
    "    'CNN': CNN_Baseline,\n",
    "}\n",
    "\n",
    "print(\"Model classes imported from src/models.py\")\n",
    "print(f\"  Available models: {list(MODEL_CLASSES.keys())}\")\n",
    "\n",
    "                                          \n",
    "                                                 \n",
    "def get_model_params_from_config():\n",
    "    \"\"\"Get model parameters from EXPERIMENT_CONFIG if available.\"\"\"\n",
    "    if 'EXPERIMENT_CONFIG' in globals() and EXPERIMENT_CONFIG is not None:\n",
    "        arch = EXPERIMENT_CONFIG.get('model_training', {}).get('architecture', {})\n",
    "        return {\n",
    "            'hidden_dim': arch.get('hidden_dim', 128),\n",
    "            'num_layers': arch.get('num_layers', 2),\n",
    "            'dropout': arch.get('dropout', 0.3),\n",
    "            'pooling': arch.get('pooling', 'mean'),\n",
    "            'num_classes': arch.get('num_classes', 2),\n",
    "        }\n",
    "    return {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.3, 'pooling': 'mean', 'num_classes': 2}\n",
    "\n",
    "class GNN_Model(nn.Module):\n",
    "    \"\"\"DEPRECATED: Use models from src/models.py instead.\n",
    "    This class is kept for backwards compatibility only.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1, hidden_dim=None, num_layers=None, dropout=None, \n",
    "                 pooling=None, num_classes=None):\n",
    "                                                                 \n",
    "        defaults = get_model_params_from_config()\n",
    "        hidden_dim = hidden_dim if hidden_dim is not None else defaults['hidden_dim']\n",
    "        num_layers = num_layers if num_layers is not None else defaults['num_layers']\n",
    "        dropout = dropout if dropout is not None else defaults['dropout']\n",
    "        pooling = pooling if pooling is not None else defaults['pooling']\n",
    "        num_classes = num_classes if num_classes is not None else defaults['num_classes']\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pooling = pooling\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        nn_1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.convs.append(GINEConv(nn_1, edge_dim=1))\n",
    "        self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            nn_i = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(GINEConv(nn_i, edge_dim=1))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        if num_classes == 2:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim // 2, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim // 2, num_classes)\n",
    "            )\n",
    "    \n",
    "    def forward_embedding(self, data):\n",
    "        \"\"\"Get graph-level embeddings before classification.\"\"\"\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        for conv, bn in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        if self.pooling == 'mean':\n",
    "            x = global_mean_pool(x, batch)\n",
    "        elif self.pooling == 'max':\n",
    "            x = global_max_pool(x, batch)\n",
    "        elif self.pooling == 'sum':\n",
    "            x = global_add_pool(x, batch)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.forward_embedding(data)\n",
    "        out = self.classifier(x)\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "print(\"Model class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataset = torch.load(dataset_path, map_location=device)\n",
    "\n",
    "test_dataset = dataset['test_dataset']\n",
    "test_labels = np.array(dataset['test_labels'])\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"{DISEASE} positive: {sum(test_labels)}\")\n",
    "print(f\"Control: {len(test_labels) - sum(test_labels)}\")\n",
    "\n",
    "import yaml\n",
    "exp_config_yaml_path = experiment_dir / \"config.yaml\" if experiment_dir.exists() else project_root / \"config.yaml\"\n",
    "if exp_config_yaml_path.exists():\n",
    "    with open(exp_config_yaml_path) as f:\n",
    "        exp_config_yaml = yaml.safe_load(f)\n",
    "    arch_config = exp_config_yaml.get('model_training', {}).get('architecture', {})\n",
    "    model_type = arch_config.get('model_type', 'GINEConv')\n",
    "    hidden_dim = arch_config.get('hidden_dim', 160)\n",
    "    num_layers = arch_config.get('num_layers', 2)\n",
    "    dropout = arch_config.get('dropout', 0.3)\n",
    "    pooling = arch_config.get('pooling', 'mean')\n",
    "    num_classes = arch_config.get('num_classes', 2)\n",
    "else:\n",
    "    model_type = 'GINEConv'\n",
    "    hidden_dim, num_layers, dropout, pooling, num_classes = 160, 2, 0.3, 'mean', 2\n",
    "\n",
    "print(f\"\\nLoading model type: {model_type}\")\n",
    "\n",
    "if model_type in MODEL_CLASSES:\n",
    "    model_class = MODEL_CLASSES[model_type]\n",
    "    \n",
    "                                                            \n",
    "    if model_type in ['MLP', 'CNN']:\n",
    "        model = model_class(\n",
    "            input_dim=1,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "    elif model_type == 'EdgeCentricRGCN':\n",
    "        model = model_class(\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout,\n",
    "            pooling=pooling\n",
    "        ).to(device)\n",
    "    else:\n",
    "        model = model_class(\n",
    "            input_dim=1,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            pooling=pooling,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "else:\n",
    "    print(f\"Unknown model type '{model_type}', falling back to legacy GNN_Model\")\n",
    "    model = GNN_Model(\n",
    "        input_dim=1,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        pooling=pooling,\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {model_type}, hidden_dim={hidden_dim}, layers={num_layers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Node Importance Analysis\n",
    "### Gradient scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing node importance across test samples...\")\n",
    "\n",
    "n_samples_to_analyze = min(50, len(test_dataset))\n",
    "all_importance_scores = []\n",
    "\n",
    "for i in range(n_samples_to_analyze):\n",
    "    data = test_dataset[i]\n",
    "    importance = compute_node_gradients(model, data, device)\n",
    "    all_importance_scores.append(importance)\n",
    "\n",
    "print(f\"Analyzed {n_samples_to_analyze} samples\")\n",
    "\n",
    "min_nodes = min(len(imp) for imp in all_importance_scores)\n",
    "trimmed_scores = [imp[:min_nodes] for imp in all_importance_scores]\n",
    "stacked_scores = np.stack(trimmed_scores)\n",
    "\n",
    "mean_importance = np.mean(stacked_scores, axis=0)\n",
    "std_importance = np.std(stacked_scores, axis=0)\n",
    "\n",
    "print(f\"Computed importance for {min_nodes} nodes\")\n",
    "print(f\"Mean importance range: [{mean_importance.min():.4f}, {mean_importance.max():.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 20\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top_indices = np.argsort(mean_importance)[::-1][:top_k]\n",
    "top_scores = mean_importance[top_indices]\n",
    "top_stds = std_importance[top_indices]\n",
    "\n",
    "labels = [f\"Node {idx}\" for idx in top_indices]\n",
    "\n",
    "y_pos = np.arange(len(top_scores))\n",
    "ax.barh(y_pos, top_scores, xerr=top_stds, align='center', \n",
    "        color='steelblue', alpha=0.8, capsize=3)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Mean Importance Score (± std)', fontsize=12)\n",
    "ax.set_title(f'Top {top_k} Important Nodes (Microbes)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz_dir = output_dir / 'visualizations'\n",
    "viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(viz_dir / 'node_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop {top_k} most important nodes:\")\n",
    "for i, (idx, score) in enumerate(zip(top_indices, top_scores)):\n",
    "    print(f\"  {i+1}. Node {idx}: {score:.4f} (±{top_stds[i]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Space Visualization\n",
    "### t-SNE projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting embeddings...\")\n",
    "\n",
    "embeddings = []\n",
    "loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        emb = model.forward_embedding(batch)\n",
    "        embeddings.append(emb.cpu().numpy())\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(\"Running t-SNE...\")\n",
    "perplexity = min(30, len(embeddings) - 1)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = ['#2ecc71', '#e74c3c']                                      \n",
    "labels_text = ['Control', DISEASE]\n",
    "\n",
    "for label in [0, 1]:\n",
    "    mask = test_labels == label\n",
    "    ax.scatter(\n",
    "        embeddings_2d[mask, 0],\n",
    "        embeddings_2d[mask, 1],\n",
    "        c=colors[label],\n",
    "        label=labels_text[label],\n",
    "        alpha=0.7,\n",
    "        s=60\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('t-SNE 1', fontsize=12)\n",
    "ax.set_ylabel('t-SNE 2', fontsize=12)\n",
    "ax.set_title('Model Embedding Space (t-SNE)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_dir / 'embedding_tsne.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Analysis\n",
    "### Misclassification review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing predictions...\")\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(test_dataset)):\n",
    "    data = test_dataset[i].to(device)\n",
    "    with torch.no_grad():\n",
    "        pred_prob = model(data).cpu().item()\n",
    "    pred_class = 1 if pred_prob > 0.5 else 0\n",
    "    predictions.append({\n",
    "        'idx': i,\n",
    "        'prob': pred_prob,\n",
    "        'pred': pred_class,\n",
    "        'true': int(test_labels[i]),\n",
    "        'correct': pred_class == int(test_labels[i])\n",
    "    })\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "accuracy = predictions_df['correct'].mean()\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Correct: {predictions_df['correct'].sum()}\")\n",
    "print(f\"Incorrect: {len(predictions_df) - predictions_df['correct'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "correct_probs = predictions_df[predictions_df['correct']]['prob']\n",
    "incorrect_probs = predictions_df[~predictions_df['correct']]['prob']\n",
    "\n",
    "ax1.hist(correct_probs, bins=20, alpha=0.7, label='Correct', color='green')\n",
    "ax1.hist(incorrect_probs, bins=20, alpha=0.7, label='Incorrect', color='red')\n",
    "ax1.axvline(x=0.5, color='black', linestyle='--', label='Decision boundary')\n",
    "ax1.set_xlabel('Prediction Probability (Disease)', fontsize=12)\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "ax1.set_title('Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "error_types = predictions_df.groupby(['true', 'pred']).size().unstack(fill_value=0)\n",
    "sns.heatmap(error_types, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['Control', DISEASE], yticklabels=['Control', DISEASE])\n",
    "ax2.set_xlabel('Predicted', fontsize=12)\n",
    "ax2.set_ylabel('True', fontsize=12)\n",
    "ax2.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_dir / 'error_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fp = ((predictions_df['true'] == 0) & (predictions_df['pred'] == 1)).sum()\n",
    "fn = ((predictions_df['true'] == 1) & (predictions_df['pred'] == 0)).sum()\n",
    "print(f\"\\nError Statistics:\")\n",
    "print(f\"  False Positives (Control -> Disease): {fp}\")\n",
    "print(f\"  False Negatives (Disease -> Control): {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Interpretation Results\n",
    "### Save summary outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_results = {\n",
    "    'experiment': EXPERIMENT_NAME,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_config': {\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout': dropout,\n",
    "        'pooling': pooling\n",
    "    },\n",
    "    'test_accuracy': float(accuracy),\n",
    "    'top_important_nodes': [\n",
    "        {'rank': i+1, 'node_index': int(idx), 'importance': float(mean_importance[idx])}\n",
    "        for i, idx in enumerate(top_indices[:20])\n",
    "    ],\n",
    "    'error_analysis': {\n",
    "        'n_correct': int(predictions_df['correct'].sum()),\n",
    "        'n_incorrect': int((~predictions_df['correct']).sum()),\n",
    "        'false_positives': int(fp),\n",
    "        'false_negatives': int(fn)\n",
    "    }\n",
    "}\n",
    "\n",
    "results_dir = output_dir / 'results'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_path = results_dir / 'interpretation_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(interpretation_results, f, indent=2)\n",
    "\n",
    "print(f\"Interpretation results saved to: {results_path}\")\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Most important node: Node {top_indices[0]} (score: {mean_importance[top_indices[0]]:.4f})\")\n",
    "print(f\"Total misclassifications: {len(predictions_df) - predictions_df['correct'].sum()}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
