{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Convert graphs to PyG datasets and split train/val/test.\n",
    "- Train a classifier with optional clinical features.\n",
    "- Save models, results, and datasets under `{DISEASE}_analysis_output/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\" PyTorch {torch.__version__} available\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU devices: {torch.cuda.device_count()}\")\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not available - please install PyTorch first\")\n",
    "    raise ImportError(\"PyTorch is required for this notebook\")\n",
    "\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.data import Data, Dataset\n",
    "    from torch_geometric.utils import from_networkx\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    from torch_geometric.nn import GCNConv, GINEConv, global_mean_pool\n",
    "    PYGEOMETRIC_AVAILABLE = True\n",
    "    print(f\" PyTorch Geometric {torch_geometric.__version__} available\")\n",
    "except ImportError:\n",
    "    PYGEOMETRIC_AVAILABLE = False\n",
    "    print(\"PyTorch Geometric not available\")\n",
    "    print(f\"Install with: pip install torch-geometric\")\n",
    "    raise ImportError(\"PyTorch Geometric is required for this notebook\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\n {DISEASE} PyTorch Geometric Dataset Construction Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "print(f\" Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\" Python version: {sys.version}\")\n",
    "print(f\" Working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "config_path = None\n",
    "if 'EXPERIMENT_CONFIG_PATH' in os.environ:\n",
    "    config_path = Path(os.environ['EXPERIMENT_CONFIG_PATH'])\n",
    "    print(f\" Using config from environment: {config_path}\")\n",
    "elif Path(\"config.yaml\").exists():\n",
    "    config_path = Path(\"config.yaml\")\n",
    "    print(f\" Found config in current directory\")\n",
    "elif Path(\"../../experiments/baseline/config.yaml\").exists():\n",
    "    config_path = Path(\"../../experiments/baseline/config.yaml\")\n",
    "    print(f\"  Using fallback config: {config_path}\")\n",
    "\n",
    "if config_path and config_path.exists():\n",
    "    print(f\" Loading experiment configuration from: {config_path}\")\n",
    "    with open(config_path, 'r') as f:\n",
    "        EXPERIMENT_CONFIG = yaml.safe_load(f)\n",
    "    print(f\" Loaded configuration for experiment\")\n",
    "    \n",
    "    # FIX: Look for disease in multiple locations\n",
    "    exp_disease = (\n",
    "        EXPERIMENT_CONFIG.get('disease') or\n",
    "        EXPERIMENT_CONFIG.get('data_extraction', {}).get('disease') or\n",
    "        EXPERIMENT_CONFIG.get('data_extraction', {}).get('disease_criteria', {}).get('disease')\n",
    "    )\n",
    "    \n",
    "    mt_config = EXPERIMENT_CONFIG.get('model_training', {})\n",
    "    arch_config = mt_config.get('architecture', {})\n",
    "    hidden_dim = arch_config.get('hidden_dim', 'N/A')\n",
    "    num_layers = arch_config.get('num_layers', 'N/A')\n",
    "    \n",
    "    print(f\"Disease from config: {exp_disease}\")\n",
    "    print(f\"Model: hidden_dim={hidden_dim}, layers={num_layers}\")\n",
    "else:\n",
    "    print(\" No experiment config found - using default parameters from notebook\")\n",
    "    EXPERIMENT_CONFIG = None\n",
    "    exp_disease = None\n",
    "\n",
    "use_clinical = False\n",
    "clinical_dim = 0\n",
    "clinical_df = None\n",
    "\n",
    "# FIX: Set DISEASE properly from config\n",
    "DISEASE = \"IBD\"  # Default\n",
    "if exp_disease:\n",
    "    DISEASE = exp_disease.upper()\n",
    "    print(f\"DISEASE set to: {DISEASE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Disease PyTorch Geometric Dataset and Training Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook converts the NetworkX graphs from `02_graph_construction.ipynb`\n",
    "into PyTorch Geometric datasets and trains a classifier for the selected\n",
    "disease. The disease and hyperparameters are loaded from the experiment config\n",
    "(`EXPERIMENT_CONFIG_PATH`) or `pipeline_config.json` when available.\n",
    "\n",
    "## Pipeline Architecture\n",
    "\n",
    "Input Data (from 02_graph_construction.ipynb)\n",
    "- NetworkX graphs (nx_graphs_{DISEASE}.pkl)\n",
    "- Labels (labels_{DISEASE}.npy)\n",
    "- Graph metadata (graph_metadata_{DISEASE}.csv)\n",
    "- Graph config (graph_config_{DISEASE}.json)\n",
    "\n",
    "Dataset/Training Pipeline:\n",
    "1. Configuration and data loading\n",
    "2. NetworkX to PyG conversion\n",
    "3. Train/val/test split\n",
    "4. Model training and evaluation\n",
    "5. Outputs and artifacts\n",
    "\n",
    "Output Files\n",
    "- pytorch_geometric/{disease}_dataset.pt\n",
    "- pytorch_geometric/train_dataset.pt\n",
    "- pytorch_geometric/val_dataset.pt\n",
    "- pytorch_geometric/test_dataset.pt\n",
    "- pytorch_geometric/dataset_statistics.json\n",
    "- results/training_history.json\n",
    "- models/best_model.pt\n",
    "- results/evaluation_results.json\n",
    "- visualizations/training_curves.png\n",
    "- visualizations/confusion_matrix_roc.png\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- PyTorch Geometric conversion from NetworkX graphs\n",
    "- Stratified splitting for balanced train/val/test sets\n",
    "- Optional clinical feature integration via `src/feature_loader.py`\n",
    "- Binary or multi-class training based on config\n",
    "- Saved artifacts for reproducibility\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed execution of `02_graph_construction.ipynb`\n",
    "- Generated files in `{DISEASE}_analysis_output/graphs/` directory\n",
    "- PyTorch and PyTorch Geometric installed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n",
    "\n",
    "### Pipeline Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_config_paths = [\n",
    "    Path(f\"{DISEASE}_analysis_output/config/pipeline_config.json\"),\n",
    "    Path(f\"../../notebooks/{DISEASE}_analysis_output/config/pipeline_config.json\"),\n",
    "]\n",
    "\n",
    "config = None\n",
    "for config_file in possible_config_paths:\n",
    "    if config_file.exists():\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(f\" Loaded configuration from: {config_file}\")\n",
    "        break\n",
    "\n",
    "if config is None:\n",
    "    print(\"No configuration file found - using default settings\")\n",
    "    config = {\n",
    "        \"disease\": \"IBD\",\n",
    "        \"output_dir\": f\"{DISEASE}_analysis_output\"\n",
    "    }\n",
    "\n",
    "DISEASE = config.get(\"disease\", \"IBD\")\n",
    "\n",
    "                                                      \n",
    "if 'EXPERIMENT_CONFIG' in globals() and EXPERIMENT_CONFIG:\n",
    "    exp_disease = EXPERIMENT_CONFIG.get('data_extraction', {}).get('disease', None)\n",
    "    if exp_disease and exp_disease != 'N/A':\n",
    "        DISEASE = exp_disease\n",
    "        print(f'Using disease from experiment config: {DISEASE}')\n",
    "\n",
    "possible_output_dirs = [\n",
    "    Path(f\"{DISEASE}_analysis_output\"),\n",
    "    Path(f\"../../notebooks/{DISEASE}_analysis_output\"),\n",
    "]\n",
    "\n",
    "output_dir = None\n",
    "for out_dir in possible_output_dirs:\n",
    "    if out_dir.exists():\n",
    "        output_dir = out_dir\n",
    "        print(f\" Found output directory: {output_dir}\")\n",
    "        break\n",
    "\n",
    "if output_dir is None:\n",
    "    output_dir = Path(config.get(\"output_dir\", f\"{DISEASE}_analysis_output\"))\n",
    "    print(f\" Using fallback output directory: {output_dir}\")\n",
    "\n",
    "GRAPHS_PKL = output_dir / \"graphs\" / f\"nx_graphs_{DISEASE}.pkl\"\n",
    "LABELS_NPY = output_dir / \"graphs\" / f\"labels_{DISEASE}.npy\"\n",
    "METADATA_CSV = output_dir / \"graphs\" / f\"graph_metadata_{DISEASE}.csv\"\n",
    "GRAPH_CONFIG_JSON = output_dir / \"graphs\" / f\"graph_config_{DISEASE}.json\"\n",
    "\n",
    "# Determine output directories based on experiment config\n",
    "experiment_output_dir = None\n",
    "if EXPERIMENT_CONFIG is not None:\n",
    "    exp_output = EXPERIMENT_CONFIG.get('output_dir')\n",
    "    if exp_output:\n",
    "        experiment_output_dir = Path(exp_output)\n",
    "        print(f\"Using experiment output directory: {experiment_output_dir}\")\n",
    "\n",
    "# Use experiment output dir if available, otherwise use disease-specific dir\n",
    "if experiment_output_dir and experiment_output_dir.exists():\n",
    "    base_output = experiment_output_dir\n",
    "else:\n",
    "    base_output = output_dir\n",
    "\n",
    "pytorch_output_dir = base_output / \"pytorch_geometric\"\n",
    "models_output_dir = base_output / \"models\"\n",
    "results_output_dir = base_output / \"results\"\n",
    "visualizations_dir = base_output / \"visualizations\"\n",
    "\n",
    "for dir_path in [pytorch_output_dir, models_output_dir, results_output_dir, visualizations_dir]:\n",
    "    dir_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"\\n Disease focus: {DISEASE}\")\n",
    "print(f\" Input directory: {output_dir}\")\n",
    "print(f\" PyTorch Geometric output: {pytorch_output_dir}\")\n",
    "print(f\" Models output: {models_output_dir}\")\n",
    "print(f\" Results output: {results_output_dir}\")\n",
    "print(f\" Visualizations directory: {visualizations_dir}\")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent) if '__file__' in globals() else str(Path.cwd().parent))\n",
    "from src.feature_loader import load_features\n",
    "\n",
    "if EXPERIMENT_CONFIG is not None:\n",
    "    print(\"\\n Checking for additional features...\")\n",
    "    features = load_features(EXPERIMENT_CONFIG, output_dir)\n",
    "    use_clinical = features['use_clinical']\n",
    "    clinical_dim = features['clinical_dim']\n",
    "    clinical_df = features['clinical']\n",
    "    \n",
    "    if use_clinical:\n",
    "        print(f\" Clinical features enabled: {clinical_dim} features\")\n",
    "        print(f\" Clinical data shape: {clinical_df.shape}\")\n",
    "    else:\n",
    "        print(f\" Microbiome only (no clinical features)\")\n",
    "else:\n",
    "    print(\"\\n Using microbiome features only (no config provided)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PARAMS = {\n",
    "    \"test_size\": 0.25,\n",
    "    \"val_size\": 0.25,\n",
    "    \"random_seed\": 42,\n",
    "    \"stratify\": True,\n",
    "    \n",
    "    \"node_feature_type\": \"weight\",\n",
    "    \"edge_feature_type\": \"weight\",\n",
    "    \"normalize_features\": True,\n",
    "    \n",
    "    \"enable_augmentation\": False,\n",
    "}\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "for key, value in DATASET_PARAMS.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    \"model_type\": \"GCN\",\n",
    "    \"hidden_dim\": 160,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.3,\n",
    "    \"pooling\": \"mean\",\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 200,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"weight_decay\": 0.000005,\n",
    "    \"patience\": 30,\n",
    "}\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in MODEL_PARAMS.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIZ_PARAMS = {\n",
    "    \"figsize\": (12, 8),\n",
    "    \"dpi\": 150,\n",
    "    \"save_plots\": True,\n",
    "    \"show_plots\": False\n",
    "}\n",
    "\n",
    "print(\"Visualization Configuration:\")\n",
    "for key, value in VIZ_PARAMS.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT_CONFIG is not None:\n",
    "    print(\"\\n Overriding parameters with experiment configuration...\")\n",
    "    \n",
    "    if \"dataset_splitting\" in EXPERIMENT_CONFIG:\n",
    "        for key, value in EXPERIMENT_CONFIG[\"dataset_splitting\"].items():\n",
    "            if key in DATASET_PARAMS:\n",
    "                DATASET_PARAMS[key] = value\n",
    "                print(f\" DATASET_PARAMS['{key}'] = {value}\")\n",
    "    \n",
    "    if \"model_training\" in EXPERIMENT_CONFIG:\n",
    "        mt_config = EXPERIMENT_CONFIG[\"model_training\"]\n",
    "        \n",
    "        if \"architecture\" in mt_config:\n",
    "            for key, value in mt_config[\"architecture\"].items():\n",
    "                if key in MODEL_PARAMS:\n",
    "                    MODEL_PARAMS[key] = value\n",
    "                    print(f\" MODEL_PARAMS['{key}'] = {value}\")\n",
    "        \n",
    "        if \"training\" in mt_config:\n",
    "            for key, value in mt_config[\"training\"].items():\n",
    "                if key in MODEL_PARAMS:\n",
    "                    MODEL_PARAMS[key] = value\n",
    "                    print(f\" MODEL_PARAMS['{key}'] = {value}\")\n",
    "        \n",
    "        if \"optimizer\" in mt_config:\n",
    "            for key, value in mt_config[\"optimizer\"].items():\n",
    "                if key in MODEL_PARAMS:\n",
    "                    MODEL_PARAMS[key] = value\n",
    "                    print(f\" MODEL_PARAMS['{key}'] = {value}\")\n",
    "    \n",
    "    print(f\" Parameters overridden with experiment config\")\n",
    "else:\n",
    "    print(\"\\n Using default parameters from notebook\")\n",
    "\n",
    "import torch\n",
    "MODEL_PARAMS[\"device\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\n Device: {MODEL_PARAMS['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Loading and Validation\n",
    "### Load graphs and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating input files...\")\n",
    "\n",
    "required_files = [\n",
    "    (GRAPHS_PKL, \"NetworkX graphs pickle\"),\n",
    "    (LABELS_NPY, \"Labels array\"),\n",
    "    (METADATA_CSV, \"Graph metadata\")\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file_path, description in required_files:\n",
    "    if file_path.exists():\n",
    "        size_mb = file_path.stat().st_size / (1024*1024)\n",
    "        print(f\" {description}: {file_path} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\" {description}: {file_path} - MISSING\")\n",
    "        missing_files.append(file_path)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n Missing required files: {len(missing_files)}\")\n",
    "    print(\"Please run notebook 01_data_extraction.ipynb first to generate these files.\")\n",
    "    raise FileNotFoundError(\"Required input files are missing\")\n",
    "else:\n",
    "    print(f\"\\n All required files found!\")\n",
    "\n",
    "print(\"\\n Loading data...\")\n",
    "\n",
    "print(f\"Loading NetworkX graphs...\")\n",
    "with open(GRAPHS_PKL, \"rb\") as f:\n",
    "    GRAPHS = pickle.load(f)\n",
    "print(f\" Loaded {len(GRAPHS):,} graphs\")\n",
    "\n",
    "print(f\"Loading labels...\")\n",
    "LABELS = np.load(LABELS_NPY)\n",
    "print(f\" Loaded {len(LABELS):,} labels\")\n",
    "\n",
    "# Check if labels should be shuffled (control experiment)\n",
    "shuffle_labels = False\n",
    "if EXPERIMENT_CONFIG is not None:\n",
    "    shuffle_labels = EXPERIMENT_CONFIG.get('data_extraction', {}).get('shuffle_labels', False)\n",
    "\n",
    "if shuffle_labels:\n",
    "    print(\" SHUFFLING LABELS (control experiment)\")\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    LABELS = np.random.permutation(LABELS)\n",
    "    print(f\" Labels shuffled - this should give ~50% accuracy if no data leakage\")\n",
    "\n",
    "print(f\"Loading metadata...\")\n",
    "metadata_df = pd.read_csv(METADATA_CSV)\n",
    "print(f\" Loaded metadata: {metadata_df.shape}\")\n",
    "\n",
    "sample_ids = metadata_df['sample_id'].tolist()\n",
    "print(f\" Extracted {len(sample_ids)} sample IDs\")\n",
    "\n",
    "print(\"\\n Validating data consistency...\")\n",
    "assert len(GRAPHS) == len(LABELS), \"Number of graphs and labels don't match!\"\n",
    "assert len(GRAPHS) == len(metadata_df), \"Number of graphs and metadata rows don't match!\"\n",
    "\n",
    "print(f\" Data validation passed\")\n",
    "print(f\" Total samples: {len(GRAPHS):,}\")\n",
    "print(f\" {DISEASE} cases (label=1): {sum(LABELS):,}\")\n",
    "print(f\" Controls (label=0): {len(LABELS) - sum(LABELS):,}\")\n",
    "print(f\"  Class balance: {sum(LABELS)/len(LABELS)*100:.1f}% {DISEASE} cases\")\n",
    "\n",
    "print(\"\\n Sample metadata:\")\n",
    "display(metadata_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## NetworkX to PyTorch Geometric Conversion\n",
    "### Prepare PyG graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing graphs for PyTorch Geometric conversion...\")\n",
    "\n",
    "def prepare_graph_for_pyg(G):\n",
    "    \"\"\"\n",
    "    Prepare a NetworkX graph for PyTorch Geometric conversion.\n",
    "    Adds integer node IDs and ensures consistent node/edge attributes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : networkx.Graph\n",
    "        Input NetworkX graph\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    networkx.Graph\n",
    "        Graph with added integer node IDs\n",
    "    \"\"\"\n",
    "    G_copy = G.copy()\n",
    "    \n",
    "    node_list = list(G_copy.nodes())\n",
    "    node_to_int = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    for node in G_copy.nodes():\n",
    "        G_copy.nodes[node]['int_id'] = node_to_int[node]\n",
    "    \n",
    "    for u, v in G_copy.edges():\n",
    "        G_copy.edges[u, v]['source_int_id'] = node_to_int[u]\n",
    "        G_copy.edges[u, v]['dest_int_id'] = node_to_int[v]\n",
    "    \n",
    "    for node in G_copy.nodes():\n",
    "        weight = G_copy.nodes[node].get('weight', 1.0)\n",
    "        while isinstance(weight, list):\n",
    "            if len(weight) == 0:\n",
    "                weight = 1.0\n",
    "                break\n",
    "            elif len(weight) == 1:\n",
    "                weight = weight[0]\n",
    "            else:\n",
    "                weight = weight[0]\n",
    "                break\n",
    "        G_copy.nodes[node]['weight'] = float(weight)\n",
    "    \n",
    "    return G_copy\n",
    "\n",
    "print(f\"Processing graphs...\")\n",
    "GRAPHS_PREPARED = []\n",
    "for i, G in enumerate(tqdm(GRAPHS, desc=\"Preparing graphs\")):\n",
    "    try:\n",
    "        G_prepared = prepare_graph_for_pyg(G)\n",
    "        GRAPHS_PREPARED.append(G_prepared)\n",
    "    except Exception as e:\n",
    "        print(f\" Error preparing graph {i}: {e}\")\n",
    "        GRAPHS_PREPARED.append(G)\n",
    "\n",
    "print(f\" Prepared {len(GRAPHS_PREPARED):,} graphs\")\n",
    "\n",
    "sample_graph = GRAPHS_PREPARED[0]\n",
    "print(f\"\\n Sample prepared graph:\")\n",
    "print(f\"Nodes: {sample_graph.number_of_nodes()}\")\n",
    "print(f\"Edges: {sample_graph.number_of_edges()}\")\n",
    "print(f\"Node attributes: {list(sample_graph.nodes(data=True))[0]}\")\n",
    "if sample_graph.number_of_edges() > 0:\n",
    "    print(f\"Edge attributes: {list(sample_graph.edges(data=True))[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### PyTorch Geometric Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrobiomeGraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Geometric dataset for disease graph classification.\n",
    "    \n",
    "    Converts NetworkX graphs to PyTorch Geometric Data objects with:\n",
    "    - Node features (normalized weights)\n",
    "    - Edge features (normalized weights)\n",
    "    - Graph-level labels (Disease vs Control)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, graphs, labels, clinical_df=None, sample_ids=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        graphs : list of networkx.Graph\n",
    "            List of prepared NetworkX graphs\n",
    "        labels : np.ndarray or list\n",
    "            Binary labels (1=Disease, 0=Control)\n",
    "        clinical_df : pd.DataFrame, optional\n",
    "            Clinical features DataFrame with\n",
    "        sample_ids : list, optional\n",
    "            List of sample IDs corresponding to each graph\n",
    "        normalize : bool\n",
    "            Whether to normalize node and edge features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels if isinstance(labels, np.ndarray) else np.array(labels)\n",
    "        self.clinical_df = clinical_df\n",
    "        self.sample_ids = sample_ids\n",
    "        self.normalize = normalize\n",
    "    \n",
    "    def get_clinical_for_sample(self, sample_id):\n",
    "        \"\"\"Get clinical features for a specific sample.\"\"\"\n",
    "        if self.clinical_df is None:\n",
    "            return None\n",
    "        \n",
    "                                                                      \n",
    "        try:\n",
    "            if sample_id in self.clinical_df.index:\n",
    "                sample_row = self.clinical_df.loc[[sample_id]]\n",
    "            elif '#SampleID' in self.clinical_df.columns:\n",
    "                sample_row = self.clinical_df[self.clinical_df['#SampleID'] == sample_id]\n",
    "            else:\n",
    "                return None\n",
    "        except (KeyError, TypeError):\n",
    "            return None\n",
    "        \n",
    "        if len(sample_row) == 0:\n",
    "            return None\n",
    "        \n",
    "                                                                                 \n",
    "        features = sample_row.values[0]\n",
    "        \n",
    "        return features.astype(np.float32)\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single graph as PyTorch Geometric Data object.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        idx : int\n",
    "            Index of the graph\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Data\n",
    "            PyTorch Geometric Data object\n",
    "        \"\"\"\n",
    "        graph = self.graphs[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        node_features = []\n",
    "        node_to_idx = {}\n",
    "        for i, (node, data) in enumerate(graph.nodes(data=True)):\n",
    "            node_to_idx[node] = i\n",
    "            weight = data.get('weight', 1.0)\n",
    "            node_features.append([weight])\n",
    "        \n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        \n",
    "        if self.normalize and node_features.numel() > 0:\n",
    "                                                                                 \n",
    "            max_val = node_features.abs().max()\n",
    "            if max_val > 0:\n",
    "                node_features = node_features / max_val\n",
    "        \n",
    "        edge_list = []\n",
    "        edge_features = []\n",
    "        \n",
    "        for u, v, data in graph.edges(data=True):\n",
    "            u_idx = node_to_idx[u]\n",
    "            v_idx = node_to_idx[v]\n",
    "            \n",
    "            edge_list.append([u_idx, v_idx])\n",
    "            edge_list.append([v_idx, u_idx])\n",
    "            \n",
    "            weight = data.get('weight', 1.0)\n",
    "            edge_features.append([weight])\n",
    "            edge_features.append([weight])\n",
    "        \n",
    "        if len(edge_list) > 0:\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "            edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "            \n",
    "            if self.normalize and edge_attr.numel() > 0:\n",
    "                max_edge = edge_attr.abs().max()\n",
    "                if max_edge > 0:\n",
    "                    edge_attr = edge_attr / max_edge\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "            edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "        \n",
    "        data = Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=torch.tensor([label], dtype=torch.float)\n",
    "        )\n",
    "        \n",
    "        if self.clinical_df is not None and self.sample_ids is not None:\n",
    "            sample_id = self.sample_ids[idx]\n",
    "            clinical_features = self.get_clinical_for_sample(sample_id)\n",
    "            if clinical_features is not None:\n",
    "                clinical_tensor = torch.tensor(clinical_features, dtype=torch.float)\n",
    "                if clinical_tensor.dim() == 0:\n",
    "                    clinical_tensor = clinical_tensor.unsqueeze(0)\n",
    "                data.clinical = clinical_tensor.flatten()\n",
    "        \n",
    "        return data\n",
    "\n",
    "print(\"MicrobiomeGraphDataset class defined\")\n",
    "print(f\"Features:\")\n",
    "print(f\"- Node features: Normalized node weights\")\n",
    "print(f\"- Edge features: Normalized edge weights\")\n",
    "print(f\"- Labels: Binary classification ({DISEASE} vs Control)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Dataset Splitting and DataLoader Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train/validation/test splits...\")\n",
    "\n",
    "test_size = DATASET_PARAMS[\"test_size\"]\n",
    "val_size = DATASET_PARAMS[\"val_size\"]\n",
    "random_seed = DATASET_PARAMS[\"random_seed\"]\n",
    "stratify = DATASET_PARAMS[\"stratify\"]\n",
    "\n",
    "stratify_labels = LABELS if stratify else None\n",
    "train_val_graphs, test_graphs, train_val_labels, test_labels, train_val_ids, test_ids = train_test_split(\n",
    "    GRAPHS_PREPARED, \n",
    "    LABELS,\n",
    "    sample_ids,\n",
    "    test_size=test_size,\n",
    "    random_state=random_seed,\n",
    "    stratify=stratify_labels\n",
    ")\n",
    "\n",
    "stratify_train_val = train_val_labels if stratify else None\n",
    "train_graphs, val_graphs, train_labels, val_labels, train_ids, val_ids = train_test_split(\n",
    "    train_val_graphs,\n",
    "    train_val_labels,\n",
    "    train_val_ids,\n",
    "    test_size=val_size,\n",
    "    random_state=random_seed,\n",
    "    stratify=stratify_train_val\n",
    ")\n",
    "\n",
    "print(f\" Dataset split complete\")\n",
    "print(f\"\\n Split statistics:\")\n",
    "print(f\"Training set: {len(train_graphs):,} samples ({len(train_graphs)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "print(f\"   - {DISEASE} cases: {sum(train_labels):,} ({sum(train_labels)/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"   - Controls: {len(train_labels) - sum(train_labels):,} ({(len(train_labels)-sum(train_labels))/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Validation set: {len(val_graphs):,} samples ({len(val_graphs)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "print(f\"   - {DISEASE} cases: {sum(val_labels):,} ({sum(val_labels)/len(val_labels)*100:.1f}%)\")\n",
    "print(f\"   - Controls: {len(val_labels) - sum(val_labels):,} ({(len(val_labels)-sum(val_labels))/len(val_labels)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Test set: {len(test_graphs):,} samples ({len(test_graphs)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "print(f\"   - {DISEASE} cases: {sum(test_labels):,} ({sum(test_labels)/len(test_labels)*100:.1f}%)\")\n",
    "print(f\"   - Controls: {len(test_labels) - sum(test_labels):,} ({(len(test_labels)-sum(test_labels))/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n Creating PyTorch Geometric datasets...\")\n",
    "train_dataset = MicrobiomeGraphDataset(\n",
    "    train_graphs, train_labels, \n",
    "    clinical_df=clinical_df if use_clinical else None,\n",
    "    sample_ids=train_ids if use_clinical else None,\n",
    "    normalize=DATASET_PARAMS[\"normalize_features\"]\n",
    ")\n",
    "val_dataset = MicrobiomeGraphDataset(\n",
    "    val_graphs, val_labels,\n",
    "    clinical_df=clinical_df if use_clinical else None,\n",
    "    sample_ids=val_ids if use_clinical else None,\n",
    "    normalize=DATASET_PARAMS[\"normalize_features\"]\n",
    ")\n",
    "test_dataset = MicrobiomeGraphDataset(\n",
    "    test_graphs, test_labels,\n",
    "    clinical_df=clinical_df if use_clinical else None,\n",
    "    sample_ids=test_ids if use_clinical else None,\n",
    "    normalize=DATASET_PARAMS[\"normalize_features\"]\n",
    ")\n",
    "\n",
    "print(f\" Created datasets\")\n",
    "print(f\"Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "print(\"\\n Testing dataset loading...\")\n",
    "sample_data = train_dataset[0]\n",
    "print(f\"Sample Data object:\")\n",
    "print(f\"- Node features shape: {sample_data.x.shape}\")\n",
    "print(f\"- Edge index shape: {sample_data.edge_index.shape}\")\n",
    "print(f\"- Edge features shape: {sample_data.edge_attr.shape}\")\n",
    "print(f\"- Label: {sample_data.y.item()}\")\n",
    "print(f\"- Number of nodes: {sample_data.num_nodes}\")\n",
    "print(f\"- Number of edges: {sample_data.num_edges}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Create DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating DataLoaders...\")\n",
    "\n",
    "batch_size = MODEL_PARAMS[\"batch_size\"]\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(random_seed)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\" DataLoaders created\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "print(\"\\n Testing batch loading...\")\n",
    "for batch in train_loader:\n",
    "    print(f\"Sample batch:\")\n",
    "    print(f\"- Batch size: {batch.num_graphs}\")\n",
    "    print(f\"- Node features shape: {batch.x.shape}\")\n",
    "    print(f\"- Edge index shape: {batch.edge_index.shape}\")\n",
    "    print(f\"- Labels shape: {batch.y.shape}\")\n",
    "    print(f\"- Batch vector shape: {batch.batch.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## GNN Model Definition\n",
    "\n",
    "### Graph Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating GNN model...\")\n",
    "\n",
    "device = torch.device(MODEL_PARAMS[\"device\"])\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_type = MODEL_PARAMS.get('model_type', 'GINEConv')\n",
    "\n",
    "num_classes = EXPERIMENT_CONFIG.get('model_training', {}).get('architecture', {}).get('num_classes', 2) if EXPERIMENT_CONFIG else 2\n",
    "use_clinical = EXPERIMENT_CONFIG.get('model_training', {}).get('architecture', {}).get('use_clinical_features', False) if EXPERIMENT_CONFIG else False\n",
    "clinical_dim = clinical_df.shape[1] if use_clinical and 'clinical_df' in dir() and clinical_df is not None else 0\n",
    "\n",
    "from src.models import (\n",
    "    GNN_GCN, GNN_GINEConv, GNN_GAT, GNN_GraphSAGE, \n",
    "    EdgeCentricRGCN, MLP_Baseline, CNN_Baseline, get_model,\n",
    "    GNN_Clinical\n",
    ")\n",
    "\n",
    "if model_type == 'MLP':\n",
    "    model = MLP_Baseline(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    print(f\" CONTROL EXPERIMENT: MLP Baseline (NO graph structure)\")\n",
    "    \n",
    "elif model_type == 'GCN':\n",
    "    model = GNN_GCN(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    print(f\" GCN model created (simple GCN, NO edge features)\")\n",
    "    \n",
    "elif model_type == 'GINEConv':\n",
    "    model = GNN_GINEConv(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    print(f\" GINEConv model created (uses edge features)\")\n",
    "    \n",
    "elif model_type == 'GAT':\n",
    "    model = GNN_GAT(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    print(f\" GAT model created (attention mechanism)\")\n",
    "    \n",
    "elif model_type == 'GraphSAGE':\n",
    "    model = GNN_GraphSAGE(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    print(f\" GraphSAGE model created\")\n",
    "    \n",
    "elif model_type == 'EdgeCentricRGCN':\n",
    "    model = EdgeCentricRGCN(\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_classes=num_classes,\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"]\n",
    "    ).to(device)\n",
    "    print(f\" EdgeCentricRGCN model created (Professor's reference)\")\n",
    "    \n",
    "elif model_type == 'CNN':\n",
    "                                                                       \n",
    "                                                 \n",
    "    max_nodes = max(data.num_nodes for data in train_dataset)\n",
    "    print(f\"CONTROL EXPERIMENT: CNN Baseline (ignores graph structure)\")\n",
    "    print(f\"   Max nodes in graphs: {max_nodes}\")\n",
    "    model = CNN_Baseline(\n",
    "        input_dim=max_nodes,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_classes=num_classes,\n",
    "        dropout=MODEL_PARAMS[\"dropout\"]\n",
    "    ).to(device)\n",
    "    print(f\" CNN_Baseline model created\")\n",
    "    \n",
    "else:\n",
    "    print(f\" Unknown model type '{model_type}', falling back to GINEConv\")\n",
    "    model = GNN_GINEConv(\n",
    "        input_dim=1,\n",
    "        hidden_dim=MODEL_PARAMS[\"hidden_dim\"],\n",
    "        num_layers=MODEL_PARAMS[\"num_layers\"],\n",
    "        dropout=MODEL_PARAMS[\"dropout\"],\n",
    "        pooling=MODEL_PARAMS[\"pooling\"],\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "print(f\"\\n   Model type: {model_type}\")\n",
    "print(f\"Hidden dimension: {MODEL_PARAMS['hidden_dim']}\")\n",
    "print(f\"Number of layers: {MODEL_PARAMS['num_layers']}\")\n",
    "print(f\"Dropout: {MODEL_PARAMS['dropout']}\")\n",
    "print(f\"Pooling: {MODEL_PARAMS['pooling']}\")\n",
    "print(f\"\\n   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Model Training\n",
    "\n",
    "### Training Loop with Early Stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device, num_classes=2):\n",
    "    \"\"\"Train for one epoch (supports binary and multi-class).\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch)\n",
    "        \n",
    "        if num_classes == 2:\n",
    "            loss = criterion(out, batch.y)\n",
    "        else:\n",
    "            loss = criterion(out, batch.y.long())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        if num_classes == 2:\n",
    "            pred = (out > 0.5).float()\n",
    "            correct += (pred == batch.y).sum().item()\n",
    "        else:\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == batch.y.long()).sum().item()\n",
    "        total += batch.num_graphs\n",
    "    \n",
    "                                                         \n",
    "    avg_loss = total_loss / total if total > 0 else 0.0\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device, num_classes=2):\n",
    "    \"\"\"Evaluate model (supports binary and multi-class).\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        out = model(batch)\n",
    "        \n",
    "        if num_classes == 2:\n",
    "            loss = criterion(out, batch.y)\n",
    "        else:\n",
    "            loss = criterion(out, batch.y.long())\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        if num_classes == 2:\n",
    "            pred = (out > 0.5).float()\n",
    "            correct += (pred == batch.y).sum().item()\n",
    "            all_probs.extend(out.cpu().numpy())\n",
    "        else:\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == batch.y.long()).sum().item()\n",
    "            all_probs.extend(F.softmax(out, dim=1).cpu().numpy())\n",
    "        total += batch.num_graphs\n",
    "        \n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "                                                         \n",
    "    avg_loss = total_loss / total if total > 0 else 0.0\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return avg_loss, accuracy, np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "print(\"Training functions defined\")\n",
    "print(f\"- train_epoch: Train for one epoch\")\n",
    "print(f\"- evaluate: Evaluate model performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up training...\")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=MODEL_PARAMS[\"learning_rate\"],\n",
    "    weight_decay=MODEL_PARAMS[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "num_classes = EXPERIMENT_CONFIG.get('model_training', {}).get('architecture', {}).get('num_classes', 2) if EXPERIMENT_CONFIG else 2\n",
    "\n",
    "if num_classes == 2:\n",
    "    criterion = nn.BCELoss()\n",
    "    print(f\"Loss function: Binary Cross-Entropy (2 classes)\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(f\"Loss function: Cross-Entropy ({num_classes} classes)\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "patience = MODEL_PARAMS[\"patience\"]\n",
    "\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Learning rate: {MODEL_PARAMS['learning_rate']}\")\n",
    "print(f\"Weight decay: {MODEL_PARAMS['weight_decay']}\")\n",
    "print(f\"Loss function: Binary Cross-Entropy\")\n",
    "print(f\"Early stopping patience: {patience} epochs\")\n",
    "\n",
    "print(f\"\\n Starting training for {MODEL_PARAMS['num_epochs']} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "num_epochs = MODEL_PARAMS[\"num_epochs\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, num_classes)\n",
    "    \n",
    "    val_loss, val_acc, val_preds, val_labels, val_probs = evaluate(model, val_loader, criterion, device, num_classes)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, models_output_dir / 'best_model.pt')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\n  Early stopping triggered at epoch {epoch+1}\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "        print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\" Training complete!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Total epochs: {epoch+1}\")\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\" Loaded best model from epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Model Evaluation and Visualization\n",
    "\n",
    "### Test Set Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "test_loss, test_acc, test_preds, test_labels, test_probs = evaluate(\n",
    "    model, test_loader, criterion, device, num_classes\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Import additional metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    roc_auc_score, \n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "try:\n",
    "    if num_classes == 2:\n",
    "        test_auc = roc_auc_score(test_labels, test_probs)\n",
    "    else:\n",
    "        test_auc = roc_auc_score(test_labels, test_probs, multi_class='ovr')\n",
    "    print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "except:\n",
    "    test_auc = None\n",
    "    print(\"AUC-ROC: N/A (requires probability scores)\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "test_balanced_acc = balanced_accuracy_score(test_labels, test_preds)\n",
    "test_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "test_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "test_recall = recall_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Test Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "target_names = [f'Class {i}' for i in range(num_classes)]\n",
    "if num_classes == 2:\n",
    "    target_names = ['Control', DISEASE]\n",
    "\n",
    "report = classification_report(\n",
    "    test_labels, \n",
    "    test_preds,\n",
    "    target_names=target_names,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_labels, \n",
    "    test_preds, \n",
    "    target_names=target_names,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Save comprehensive evaluation results\n",
    "evaluation_results = {\n",
    "    'test_loss': float(test_loss),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_balanced_accuracy': float(test_balanced_acc),\n",
    "    'test_f1_score': float(test_f1),\n",
    "    'test_precision': float(test_precision),\n",
    "    'test_recall': float(test_recall),\n",
    "    'test_auc_roc': float(test_auc) if test_auc is not None else None,\n",
    "    'classification_report': report,\n",
    "    'confusion_matrix': conf_matrix.tolist(),\n",
    "    'num_test_samples': len(test_labels),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "results_path = results_output_dir / 'evaluation_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nEvaluation results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Cross-Validation Evaluation\n",
    "### k-fold runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_cv = False\n",
    "cv_results = None\n",
    "\n",
    "if EXPERIMENT_CONFIG is not None:\n",
    "    eval_config = EXPERIMENT_CONFIG.get('model_training', {}).get('evaluation', {})\n",
    "    enable_cv = eval_config.get('enable_cross_validation', False)\n",
    "    n_folds = eval_config.get('n_folds', 5)\n",
    "    num_runs_per_fold = eval_config.get('num_runs_per_experiment', 1)\n",
    "\n",
    "if enable_cv:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Running Cross-Validation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Folds: {n_folds}\")\n",
    "    print(f\"Runs per fold: {num_runs_per_fold}\")\n",
    "    \n",
    "    import sys\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "    try:\n",
    "        from src.cross_validation import run_kfold_experiment, save_cv_results\n",
    "        \n",
    "        all_graphs = GRAPHS_PREPARED\n",
    "                                                                                                    \n",
    "        all_labels = LABELS\n",
    "        \n",
    "        if use_clinical and clinical_dim > 0:\n",
    "            model_class = GNN_Clinical\n",
    "            model_kwargs = {\n",
    "                'input_dim': 1,\n",
    "                'hidden_dim': MODEL_PARAMS['hidden_dim'],\n",
    "                'num_layers': MODEL_PARAMS['num_layers'],\n",
    "                'dropout': MODEL_PARAMS['dropout'],\n",
    "                'pooling': MODEL_PARAMS['pooling'],\n",
    "                'clinical_dim': clinical_dim,\n",
    "                'clinical_hidden_dim': MODEL_PARAMS.get('clinical_hidden_dim', 32),\n",
    "                'num_classes': num_classes\n",
    "            }\n",
    "        else:\n",
    "            model_class = GNN_GINEConv\n",
    "            model_kwargs = {\n",
    "                'input_dim': 1,\n",
    "                'hidden_dim': MODEL_PARAMS['hidden_dim'],\n",
    "                'num_layers': MODEL_PARAMS['num_layers'],\n",
    "                'dropout': MODEL_PARAMS['dropout'],\n",
    "                'pooling': MODEL_PARAMS['pooling'],\n",
    "                'num_classes': num_classes\n",
    "            }\n",
    "        \n",
    "        training_kwargs = {\n",
    "            'batch_size': MODEL_PARAMS['batch_size'],\n",
    "            'learning_rate': MODEL_PARAMS['learning_rate'],\n",
    "            'weight_decay': MODEL_PARAMS['weight_decay'],\n",
    "            'num_epochs': MODEL_PARAMS['num_epochs'],\n",
    "            'early_stopping_patience': MODEL_PARAMS.get('patience', 30)\n",
    "        }\n",
    "        \n",
    "        cv_results = run_kfold_experiment(\n",
    "            graphs=all_graphs,\n",
    "            labels=all_labels,\n",
    "            model_class=model_class,\n",
    "            model_params=model_kwargs,\n",
    "            training_params=training_kwargs,\n",
    "            n_folds=n_folds,\n",
    "            num_runs_per_fold=num_runs_per_fold,\n",
    "            random_seed=random_seed,\n",
    "            device=device,\n",
    "            num_classes=num_classes,\n",
    "            output_dir=results_output_dir / 'cross_validation',\n",
    "            verbose=True,\n",
    "            dataset_class=MicrobiomeGraphDataset,\n",
    "            clinical_df=clinical_df if use_clinical else None,\n",
    "            sample_ids=sample_ids if use_clinical else None\n",
    "        )\n",
    "        \n",
    "        cv_path = results_output_dir / 'cv_results.json'\n",
    "        save_cv_results(cv_results, cv_path)\n",
    "        print(f\"\\n Cross-validation results saved to: {cv_path}\")\n",
    "        \n",
    "        evaluation_results['cross_validation'] = {\n",
    "            'enabled': True,\n",
    "            'n_folds': n_folds,\n",
    "            'num_runs_per_fold': num_runs_per_fold,\n",
    "            'aggregated': cv_results.get('aggregated', {})\n",
    "        }\n",
    "        \n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(evaluation_results, f, indent=2)\n",
    "        print(f\" Updated evaluation results with cross-validation metrics\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"  Cross-validation module not available: {e}\")\n",
    "        print(f\"Skipping cross-validation...\")\n",
    "    except Exception as e:\n",
    "        print(f\" Cross-validation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\n Cross-validation disabled (set enable_cross_validation: true in config to enable)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Training Curves Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating training visualization...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=VIZ_PARAMS[\"figsize\"])\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if VIZ_PARAMS[\"save_plots\"]:\n",
    "    plot_path = visualizations_dir / \"training_curves.png\"\n",
    "    plt.savefig(plot_path, dpi=VIZ_PARAMS[\"dpi\"], bbox_inches='tight')\n",
    "    print(f\" Saved training curves to: {plot_path}\")\n",
    "\n",
    "if VIZ_PARAMS[\"show_plots\"]:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "print(f\" Training curves generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Confusion Matrix and ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating evaluation visualizations...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=VIZ_PARAMS[\"figsize\"])\n",
    "\n",
    "cm_labels = ['Control', disease_label] if 'disease_label' in dir() else ['Control', 'Case']\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=cm_labels, \n",
    "            yticklabels=cm_labels,\n",
    "            ax=ax1, cbar_kws={'label': 'Count'})\n",
    "ax1.set_xlabel('Predicted', fontsize=12)\n",
    "ax1.set_ylabel('Actual', fontsize=12)\n",
    "ax1.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "if test_auc is not None:\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, test_probs)\n",
    "    \n",
    "    ax2.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {test_auc:.4f})')\n",
    "    ax2.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "    ax2.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax2.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'ROC Curve\\nCould not be computed', \n",
    "             ha='center', va='center', fontsize=14)\n",
    "    ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if VIZ_PARAMS[\"save_plots\"]:\n",
    "    plot_path = visualizations_dir / \"confusion_matrix_roc.png\"\n",
    "    plt.savefig(plot_path, dpi=VIZ_PARAMS[\"dpi\"], bbox_inches='tight')\n",
    "    print(f\" Saved confusion matrix and ROC curve to: {plot_path}\")\n",
    "\n",
    "if VIZ_PARAMS[\"show_plots\"]:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "print(f\" Evaluation visualizations generated\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 9: Output Generation and Pipeline Summary\n",
    "\n",
    "### Save Dataset and Model Artifacts\n",
    "\n",
    "Save the processed dataset, trained model, and all artifacts for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving processed datasets...\")\n",
    "\n",
    "torch.save({\n",
    "    'train_dataset': train_dataset,\n",
    "    'val_dataset': val_dataset,\n",
    "    'test_dataset': test_dataset,\n",
    "    'train_graphs': train_graphs,\n",
    "    'val_graphs': val_graphs,\n",
    "    'test_graphs': test_graphs,\n",
    "    'train_labels': train_labels,\n",
    "    'val_labels': val_labels,\n",
    "    'test_labels': test_labels\n",
    "}, pytorch_output_dir / f'{DISEASE.lower()}_dataset.pt')\n",
    "\n",
    "print(f\" Complete dataset saved to: {pytorch_output_dir / f'{DISEASE.lower()}_dataset.pt'}\")\n",
    "\n",
    "torch.save(train_dataset, pytorch_output_dir / 'train_dataset.pt')\n",
    "torch.save(val_dataset, pytorch_output_dir / 'val_dataset.pt')\n",
    "torch.save(test_dataset, pytorch_output_dir / 'test_dataset.pt')\n",
    "\n",
    "print(f\" Individual splits saved\")\n",
    "\n",
    "dataset_stats = {\n",
    "    'total_samples': len(GRAPHS_PREPARED),\n",
    "    'train_samples': len(train_dataset),\n",
    "    'val_samples': len(val_dataset),\n",
    "    'test_samples': len(test_dataset),\n",
    "    'train_case_ratio': float(sum(train_labels) / len(train_labels)),\n",
    "    'val_case_ratio': float(sum(val_labels) / len(val_labels)),\n",
    "    'test_case_ratio': float(sum(test_labels) / len(test_labels)),\n",
    "    'avg_nodes': float(np.mean([G.number_of_nodes() for G in GRAPHS_PREPARED])),\n",
    "    'avg_edges': float(np.mean([G.number_of_edges() for G in GRAPHS_PREPARED])),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "stats_path = pytorch_output_dir / 'dataset_statistics.json'\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(dataset_stats, f, indent=2)\n",
    "\n",
    "print(f\" Dataset statistics saved to: {stats_path}\")\n",
    "\n",
    "history_path = results_output_dir / 'training_history.json'\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\" Training history saved to: {history_path}\")\n",
    "\n",
    "print(f\"\\n All outputs saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Pipeline Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{DISEASE} PyTorch Geometric Pipeline Complete!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n Dataset Summary:\")\n",
    "print(f\"Disease: {DISEASE}\")\n",
    "print(f\"Total graphs: {len(GRAPHS_PREPARED):,}\")\n",
    "print(f\"Training set: {len(train_dataset):,} ({len(train_dataset)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(val_dataset):,} ({len(val_dataset)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(test_dataset):,} ({len(test_dataset)/len(GRAPHS_PREPARED)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n Graph Statistics:\")\n",
    "print(f\"Average nodes per graph: {dataset_stats['avg_nodes']:.1f}\")\n",
    "print(f\"Average edges per graph: {dataset_stats['avg_edges']:.1f}\")\n",
    "print(f\"Node feature dimension: 1 (normalized weights)\")\n",
    "print(f\"Edge feature dimension: 1 (normalized weights)\")\n",
    "\n",
    "print(f\"\\n Model Summary:\")\n",
    "print(f\"Architecture: GNN with GINEConv layers\")\n",
    "print(f\"Hidden dimension: {MODEL_PARAMS['hidden_dim']}\")\n",
    "print(f\"Number of layers: {MODEL_PARAMS['num_layers']}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\n Training Results:\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Total epochs: {len(history['train_loss'])}\")\n",
    "\n",
    "print(f\"\\n Test Set Performance:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "if test_auc is not None:\n",
    "    print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n Output Directory Structure:\")\n",
    "print(f\"{output_dir}/\")\n",
    "print(f\" pytorch_geometric/\")\n",
    "print(f\"{DISEASE.lower()}_dataset.pt\")\n",
    "print(f\"train_dataset.pt\")\n",
    "print(f\"val_dataset.pt\")\n",
    "print(f\"test_dataset.pt\")\n",
    "print(f\"dataset_statistics.json\")\n",
    "print(f\"dataset_config.json\")\n",
    "print(f\" models/\")\n",
    "print(f\"best_model.pt\")\n",
    "print(f\" results/\")\n",
    "print(f\"evaluation_results.json\")\n",
    "print(f\"training_history.json\")\n",
    "print(f\" visualizations/\")\n",
    "print(f\" dataset_analysis/\")\n",
    "print(f\"     training_curves.png\")\n",
    "print(f\"     confusion_matrix_roc.png\")\n",
    "\n",
    "print(f\"\\n Next Steps:\")\n",
    "print(f\"1. Analyze the trained model performance\")\n",
    "print(f\"2. Use the saved model for inference on new samples\")\n",
    "print(f\"3. Experiment with different model architectures\")\n",
    "print(f\"4. Fine-tune hyperparameters for better performance\")\n",
    "print(f\"5. Explore feature importance and graph structure analysis\")\n",
    "\n",
    "print(f\"\\n Model Loading:\")\n",
    "print(f\"To load the best model:\")\n",
    "print(f\"```python\")\n",
    "print(f\"checkpoint = torch.load('{models_output_dir}/best_model.pt')\")\n",
    "print(f\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
    "print(f\"```\")\n",
    "\n",
    "print(f\"\\n Dataset Loading:\")\n",
    "print(f\"To load the dataset:\")\n",
    "print(f\"```python\")\n",
    "print(f\"data = torch.load('{pytorch_output_dir}/{DISEASE.lower()}_dataset.pt')\")\n",
    "print(f\"train_dataset = data['train_dataset']\")\n",
    "print(f\"```\")\n",
    "\n",
    "print(f\"\\n Pipeline completed successfully!\")\n",
    "print(f\" Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}